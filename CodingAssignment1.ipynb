{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "path = 'flowers17/feats/'\n",
    "\n",
    "img_shuffle = []\n",
    "img_set = []\n",
    "class_counter = 0\n",
    "counter = 0\n",
    "for filename in sorted(os.listdir(path)):\n",
    "    img_set.append(filename)\n",
    "    counter += 1\n",
    "    if counter == 80:\n",
    "        shuffle(img_set)\n",
    "        new_class = [deepcopy(img_set[0:40]), deepcopy(img_set[40:60]), deepcopy(img_set[60:80])]\n",
    "        img_shuffle.append(new_class)\n",
    "        img_set = []\n",
    "        class_counter += 1\n",
    "        counter = 0\n",
    "\n",
    "flower_feats = deepcopy(img_shuffle)\n",
    "for i in range(len(img_shuffle)):\n",
    "    for j in range(len(img_shuffle[i])):\n",
    "        for k in range(len(img_shuffle[i][j])):\n",
    "            file = np.load(path + '/' + img_shuffle[i][j][k])\n",
    "            flower_feats[i][j][k] = file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_models(flower_feats, c):\n",
    "    binary_svm = []\n",
    "    for i in range(17):\n",
    "        clf = SVC(C=c, kernel='linear', probability=True)\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        for j in range(17):\n",
    "            if i == j:\n",
    "                train_x += flower_feats[j][0]\n",
    "                train_y += [1]*len(flower_feats[j][0])\n",
    "            else:\n",
    "                train_x += flower_feats[j][0]\n",
    "                train_y += [0]*len(flower_feats[j][0])\n",
    "        clf.fit(train_x, train_y)\n",
    "        binary_svm.append(clf)\n",
    "    return binary_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "binary_svm = train_new_models(flower_feats, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(all_svm, features):\n",
    "    class_prediction = []\n",
    "    for i in range(len(all_svm)):\n",
    "        current_prob = all_svm[i].predict_proba(features)\n",
    "        if len(class_prediction) == 0:\n",
    "            for probabilities in current_prob:\n",
    "                class_prediction.append((i, probabilities[1]))\n",
    "        else:\n",
    "            for j in range(len(current_prob)):\n",
    "                if class_prediction[j][1] < current_prob[j][1]:\n",
    "                    class_prediction[j] = (i, current_prob[j][1])\n",
    "                \n",
    "    output = [prediction[0] for prediction in class_prediction]\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_score(all_svm, flower_feats):\n",
    "    y_predict = []\n",
    "    y_true = []\n",
    "    for i in range(len(flower_feats)):\n",
    "        prediction = predict_class(all_svm, flower_feats[i][1])\n",
    "        y_predict += prediction\n",
    "        y_true += [i] * len(prediction)\n",
    "    \n",
    "    return accuracy_score(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205882352941176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing validation using c = 1\n",
    "validation_score(binary_svm, flower_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C values to use\n",
    "c_values = [0.01, 0.1, 0.1**0.5, 1, 10**0.5, 10, 100**0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c value:0.01    score:0.9352941176470588\n",
      "c value:0.1    score:0.9205882352941176\n",
      "c value:0.31622776601683794    score:0.9176470588235294\n",
      "c value:1    score:0.9235294117647059\n",
      "c value:3.1622776601683795    score:0.9235294117647059\n",
      "c value:10    score:0.9176470588235294\n",
      "c value:10.0    score:0.9235294117647059\n",
      "(0.01, 0.9352941176470588)\n"
     ]
    }
   ],
   "source": [
    "# Finding best C\n",
    "best_c = (0,0)\n",
    "for c in c_values:\n",
    "    test_svm = train_new_models(flower_feats, c)\n",
    "    c_score = validation_score(test_svm, flower_feats)\n",
    "    print('c value:{}    score:{}'.format(c, c_score))\n",
    "    if c_score > best_c[1]:\n",
    "        best_c = (c, c_score)\n",
    "print(best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_models(flower_feats, c):\n",
    "    binary_svm = []\n",
    "    for i in range(17):\n",
    "        clf = SVC(C=c, kernel='linear', probability=True)\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        for j in range(17):\n",
    "            if i == j:\n",
    "                train_x += flower_feats[j][0]\n",
    "                train_x += flower_feats[j][1]\n",
    "                train_y += [1]*len(flower_feats[j][0])\n",
    "                train_y += [1]*len(flower_feats[j][1])\n",
    "            else:\n",
    "                train_x += flower_feats[j][0]\n",
    "                train_x += flower_feats[j][1]\n",
    "                train_y += [0]*len(flower_feats[j][0])\n",
    "                train_y += [0]*len(flower_feats[j][1])\n",
    "        clf.fit(train_x, train_y)\n",
    "        binary_svm.append(clf)\n",
    "    return binary_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(all_svm, flower_feats):\n",
    "    y_predict = []\n",
    "    y_true = []\n",
    "    for i in range(len(flower_feats)):\n",
    "        prediction = predict_class(all_svm, flower_feats[i][2])\n",
    "        y_predict += prediction\n",
    "        y_true += [i] * len(prediction)\n",
    "        img_shown = 0\n",
    "        for j in range(len(prediction)):\n",
    "            if prediction[j] != i:\n",
    "                print('{} wrongly classified for class {}'.format(img_shuffle[i][2][j],i))\n",
    "    \n",
    "    return accuracy_score(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_0071.jpg_ft.npy wrongly classified for class 0\n",
      "image_0050.jpg_ft.npy wrongly classified for class 0\n",
      "image_0070.jpg_ft.npy wrongly classified for class 0\n",
      "image_0020.jpg_ft.npy wrongly classified for class 0\n",
      "image_0118.jpg_ft.npy wrongly classified for class 1\n",
      "image_0199.jpg_ft.npy wrongly classified for class 2\n",
      "image_0225.jpg_ft.npy wrongly classified for class 2\n",
      "image_0187.jpg_ft.npy wrongly classified for class 2\n",
      "image_0252.jpg_ft.npy wrongly classified for class 3\n",
      "image_0335.jpg_ft.npy wrongly classified for class 4\n",
      "image_0397.jpg_ft.npy wrongly classified for class 4\n",
      "image_0573.jpg_ft.npy wrongly classified for class 7\n",
      "image_0605.jpg_ft.npy wrongly classified for class 7\n",
      "image_0577.jpg_ft.npy wrongly classified for class 7\n",
      "image_0870.jpg_ft.npy wrongly classified for class 10\n",
      "image_0911.jpg_ft.npy wrongly classified for class 11\n",
      "image_0953.jpg_ft.npy wrongly classified for class 11\n",
      "image_1024.jpg_ft.npy wrongly classified for class 12\n",
      "image_1030.jpg_ft.npy wrongly classified for class 12\n",
      "image_1043.jpg_ft.npy wrongly classified for class 13\n",
      "image_1052.jpg_ft.npy wrongly classified for class 13\n",
      "image_1167.jpg_ft.npy wrongly classified for class 14\n",
      "image_1172.jpg_ft.npy wrongly classified for class 14\n",
      "image_1356.jpg_ft.npy wrongly classified for class 16\n",
      "image_1357.jpg_ft.npy wrongly classified for class 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9264705882352942"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with training and validation set\n",
    "final_svm = train_final_models(flower_feats, best_c[0])\n",
    "# Scoring the final model\n",
    "test_score(final_svm, flower_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving train, val, test data\n",
    "save_path = 'train_val_test'\n",
    "counter = 0\n",
    "for splits in flower_feats:\n",
    "    np.save(save_path + '/' + 'train_class{}'.format(counter), splits[0])\n",
    "    np.save(save_path + '/' + 'val_class{}'.format(counter), splits[1])\n",
    "    np.save(save_path + '/' + 'test_class{}'.format(counter), splits[2])\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
